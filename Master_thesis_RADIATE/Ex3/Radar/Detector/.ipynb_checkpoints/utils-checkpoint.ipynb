{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b689649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import time\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import natsort\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98593c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([ \n",
    "        transforms.ToTensor() \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c67117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_box(obj):\n",
    "    \n",
    "    xmin = float(obj.find('xmin').text)\n",
    "    ymin = float(obj.find('ymin').text)\n",
    "    xmax = float(obj.find('xmax').text)\n",
    "    ymax = float(obj.find('ymax').text)\n",
    "    \n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def generate_label(obj):\n",
    "\n",
    "    if obj.find('name').text == \"vehicle\":\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "def generate_target(file): \n",
    "    with open(file) as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, \"html.parser\")\n",
    "        objects = soup.find_all(\"object\")\n",
    "        num_objs = len(objects)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in objects:\n",
    "            boxes.append(generate_box(i))\n",
    "            labels.append(generate_label(i))\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32) \n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64) \n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        \n",
    "        return target\n",
    "\n",
    "class RadarDataset(object):\n",
    "    def __init__(self, transforms, path):\n",
    "        self.transforms = transforms\n",
    "        self.path = path\n",
    "        self.imgs = list(sorted(os.listdir(self.path)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_image = self.imgs[idx]\n",
    "        file_label = self.imgs[idx][:-3] + 'xml'\n",
    "        img_path = os.path.join(self.path, file_image)\n",
    "        \n",
    "        if 'val' in self.path:\n",
    "            label_path = os.path.join(\"./\"+weather+\"/annotations_val/\", file_label)\n",
    "        elif 'test' in self.path:\n",
    "            label_path = os.path.join(\"./\"+weather+\"/annotations_test/\", file_label)\n",
    "        else:\n",
    "            label_path = os.path.join(\"./\"+weather+\"/annotations_train/\", file_label)\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        target = generate_target(label_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "  \n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84405a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_statistics(outputs, targets, iou_threshold):\n",
    "    \"\"\" Compute true positives, predicted scores and predicted labels per sample \"\"\"\n",
    "    batch_metrics = []\n",
    "    for sample_i in range(len(outputs)):  # outputs=preds_adj_all, targets=annot_all\n",
    "\n",
    "        if outputs[sample_i] is None:\n",
    "            continue\n",
    "\n",
    "        output = outputs[sample_i] # predict\n",
    "        # pred_boxes = output['boxes']\n",
    "        # pred_scores = output['scores']\n",
    "        # pred_labels = output['labels']\n",
    "\n",
    "        true_positives = torch.zeros(output['boxes'].shape[0])   # The number of predicted objects\n",
    "        annotations = targets[sample_i]  # ground-truth\n",
    "        target_labels = annotations['labels'] if len(annotations) else []\n",
    "        if len(annotations):    # len(annotations) = 3\n",
    "            detected_boxes = []\n",
    "            target_boxes = annotations['boxes']\n",
    "\n",
    "            for pred_i, (pred_box, pred_label) in enumerate(zip(output['boxes'], output['labels'])): \n",
    "                \n",
    "                # If targets are found break\n",
    "                if len(detected_boxes) == len(target_labels): # annotations -> target_labels\n",
    "                    break\n",
    "\n",
    "                # Ignore if label is not one of the target labels\n",
    "                if pred_label not in target_labels:\n",
    "                    continue\n",
    "\n",
    "                iou, box_index = bbox_iou(pred_box.unsqueeze(0), target_boxes).max(0)\n",
    "                if iou >= iou_threshold and box_index not in detected_boxes:\n",
    "                    true_positives[pred_i] = 1\n",
    "                    detected_boxes += [box_index]\n",
    "        batch_metrics.append([true_positives, output['scores'], output['labels']])\n",
    "    return batch_metrics\n",
    "\n",
    "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
    "    \"\"\"\n",
    "    Returns the IoU of two bounding boxes\n",
    "    \"\"\"\n",
    "    if not x1y1x2y2:\n",
    "        # Transform from center and width to exact coordinates\n",
    "        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "    else:\n",
    "        # Get the coordinates of bounding boxes\n",
    "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "\n",
    "    # get the corrdinates of the intersection rectangle\n",
    "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "    # Intersection area\n",
    "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n",
    "    # Union Area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "    iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def ap_per_class(tp, conf, pred_cls, target_cls):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n",
    "    # Arguments\n",
    "        tp:    True positives (list).\n",
    "        conf:  Objectness value from 0-1 (list).\n",
    "        pred_cls: Predicted object classes (list).\n",
    "        target_cls: True object classes (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by objectness\n",
    "    i = torch.argsort(-conf)\n",
    "    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n",
    "\n",
    "    # Find unique classes\n",
    "    unique_classes = torch.unique(target_cls)  \n",
    "    \n",
    "    # Create Precision-Recall curve and compute AP for each class\n",
    "    ap, p, r = [], [], []\n",
    "    for c in unique_classes:\n",
    "        i = pred_cls == c\n",
    "        n_gt = (target_cls == c).sum()  # Number of ground truth objects\n",
    "        n_p = i.sum()  # Number of predicted objects\n",
    "\n",
    "        if n_p == 0 and n_gt == 0:\n",
    "            continue\n",
    "        elif n_p == 0 or n_gt == 0:\n",
    "            ap.append(0)\n",
    "            r.append(0)\n",
    "            p.append(0)\n",
    "        else:\n",
    "            # Accumulate FPs and TPs\n",
    "            fpc = torch.cumsum(1 - tp[i],-1)\n",
    "            tpc = torch.cumsum(tp[i],-1)\n",
    "\n",
    "            # Recall\n",
    "            recall_curve = tpc / (n_gt + 1e-16)\n",
    "            r.append(recall_curve[-1])\n",
    "\n",
    "            # Precision\n",
    "            precision_curve = tpc / (tpc + fpc)\n",
    "            p.append(precision_curve[-1])\n",
    "\n",
    "            # AP from recall-precision curve\n",
    "            ap.append(compute_ap(recall_curve, precision_curve))\n",
    "\n",
    "    # Compute F1 score (harmonic mean of precision and recall)\n",
    "    p, r, ap = torch.tensor(np.array(p)), torch.tensor(np.array(r)), torch.tensor(np.array(ap))\n",
    "    f1 = 2 * p * r / (p + r + 1e-16)\n",
    "\n",
    "    return p, r, ap, f1, unique_classes\n",
    "\n",
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precision, [0.0]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "def make_prediction(model, img, threshold):\n",
    "    model.eval()\n",
    "    preds = model(img)\n",
    "    for id in range(len(preds)) :\n",
    "        idx_list = []\n",
    "\n",
    "        for idx, score in enumerate(preds[id]['scores']) :\n",
    "            if score > threshold : \n",
    "                idx_list.append(idx)\n",
    "\n",
    "        preds[id]['boxes'] = preds[id]['boxes'][idx_list]\n",
    "        preds[id]['labels'] = preds[id]['labels'][idx_list]\n",
    "        preds[id]['scores'] = preds[id]['scores'][idx_list]\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a21b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadarDataset_fog(object):\n",
    "    def __init__(self, transforms, path):\n",
    "        self.transforms = transforms\n",
    "        self.path = path\n",
    "        self.imgs = list(sorted(os.listdir(self.path)))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_image = self.imgs[idx]\n",
    "        file_label = self.imgs[idx][:-3] + 'xml'\n",
    "        \n",
    "        img_path = os.path.join(self.path, file_image)\n",
    "        label_path = os.path.join('./dataset/test/test_annot_classified/fog/', file_label)\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        target = generate_target(label_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "class RadarDataset_rain(object):\n",
    "    def __init__(self, transforms, path):\n",
    "        self.transforms = transforms\n",
    "        self.path = path\n",
    "        self.imgs = list(sorted(os.listdir(self.path)))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_image = self.imgs[idx]\n",
    "        file_label = self.imgs[idx][:-3] + 'xml'\n",
    "        \n",
    "        img_path = os.path.join(self.path, file_image)\n",
    "        label_path = os.path.join('./dataset/test/test_annot_classified/rain/', file_label)\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        target = generate_target(label_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)\n",
    "\n",
    "data_transform = transforms.Compose([ \n",
    "        transforms.ToTensor() \n",
    "    ])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "class RadarDataset_sunny(object):\n",
    "    def __init__(self, transforms, path):\n",
    "        self.transforms = transforms\n",
    "        self.path = path\n",
    "        self.imgs = list(sorted(os.listdir(self.path)))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_image = self.imgs[idx]\n",
    "        file_label = self.imgs[idx][:-3] + 'xml'\n",
    "        \n",
    "        img_path = os.path.join(self.path, file_image)\n",
    "        label_path = os.path.join('./dataset/test/test_annot_classified/sunny/', file_label)\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        target = generate_target(label_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "class RadarDataset_night(object):\n",
    "    def __init__(self, transforms, path):\n",
    "        self.transforms = transforms\n",
    "        self.path = path\n",
    "        self.imgs = list(sorted(os.listdir(self.path)))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_image = self.imgs[idx]\n",
    "        file_label = self.imgs[idx][:-3] + 'xml'\n",
    "        \n",
    "        img_path = os.path.join(self.path, file_image)\n",
    "        label_path = os.path.join('./dataset/test/test_annot_classified/night/', file_label)\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        target = generate_target(label_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
