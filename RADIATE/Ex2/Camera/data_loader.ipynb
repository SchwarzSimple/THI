{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b38242",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([ \n",
    "        transforms.ToTensor() \n",
    "    ])\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):  \n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23c5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_box(obj):\n",
    "    \n",
    "    xmin = float(obj.find('xmin').text)\n",
    "    ymin = float(obj.find('ymin').text)\n",
    "    xmax = float(obj.find('xmax').text)\n",
    "    ymax = float(obj.find('ymax').text)\n",
    "    \n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def generate_label(obj):\n",
    "\n",
    "    if obj.find('name').text == \"vehicle\":\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def generate_target(file): \n",
    "    with open(file) as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, \"html.parser\")\n",
    "        objects = soup.find_all(\"object\")\n",
    "\n",
    "        num_objs = len(objects)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in objects:\n",
    "            boxes.append(generate_box(i))\n",
    "            labels.append(generate_label(i))\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32) \n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        \n",
    "        return target\n",
    "\n",
    "def generate_weather(file):\n",
    "    with open(file) as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, \"html.parser\")\n",
    "        weather = soup.find(\"weather\")\n",
    "        weather = weather.string\n",
    "        \n",
    "        return weather\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadarDataset(object):\n",
    "    def __init__(self, transforms, path):\n",
    "        self.transforms = transforms\n",
    "        self.path = path\n",
    "        self.imgs = list(sorted(os.listdir(self.path)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_image = self.imgs[idx]\n",
    "        file_label = self.imgs[idx][:-3] + 'xml'\n",
    "        img_path = os.path.join(self.path, file_image)\n",
    "        \n",
    "        if 'val' in self.path:\n",
    "            label_path = os.path.join(\"./data/annotations_val/\", file_label)\n",
    "        elif 'test' in self.path:\n",
    "            label_path = os.path.join(\"./data/annotations_test/\", file_label)\n",
    "        else:\n",
    "            label_path = os.path.join(\"./data/annotations_train/\", file_label)\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        target = generate_target(label_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        weather = generate_weather(label_path)\n",
    "\n",
    "        return weather, img, target\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "def fastrcnn_loss(class_logits, box_regression, labels, regression_targets):\n",
    "    # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]\n",
    "    \"\"\"\n",
    "    Computes the loss for Faster R-CNN.\n",
    "    Args:\n",
    "        class_logits (Tensor)\n",
    "        box_regression (Tensor)\n",
    "        labels (list[BoxList])\n",
    "        regression_targets (Tensor)\n",
    "    Returns:\n",
    "        classification_loss (Tensor)\n",
    "        box_loss (Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    regression_targets = torch.cat(regression_targets, dim=0)\n",
    "\n",
    "    classification_loss = F.cross_entropy(class_logits, labels)\n",
    "\n",
    "    # get indices that correspond to the regression targets for\n",
    "    # the corresponding ground truth labels, to be used with\n",
    "    # advanced indexing\n",
    "    sampled_pos_inds_subset = torch.where(labels > 0)[0]\n",
    "    labels_pos = labels[sampled_pos_inds_subset]\n",
    "    N, num_classes = class_logits.shape\n",
    "    box_regression = box_regression.reshape(N, box_regression.size(-1) // 4, 4)\n",
    "\n",
    "    box_loss = F.smooth_l1_loss(\n",
    "        box_regression[sampled_pos_inds_subset, labels_pos],\n",
    "        regression_targets[sampled_pos_inds_subset],\n",
    "        beta=1 / 9,\n",
    "        reduction=\"sum\",\n",
    "    )\n",
    "    box_loss = box_loss / labels.numel()\n",
    "\n",
    "    return classification_loss, box_loss\n",
    "\n",
    "def permute_and_flatten(layer: Tensor, N: int, A: int, C: int, H: int, W: int) -> Tensor:\n",
    "    layer = layer.view(N, -1, C, H, W)\n",
    "    layer = layer.permute(0, 3, 4, 1, 2)\n",
    "    layer = layer.reshape(N, -1, C)\n",
    "    return layer\n",
    "\n",
    "def concat_box_prediction_layers(box_cls: List[Tensor], box_regression: List[Tensor]) -> Tuple[Tensor, Tensor]:\n",
    "    box_cls_flattened = []\n",
    "    box_regression_flattened = []\n",
    "    # for each feature level, permute the outputs to make them be in the\n",
    "    # same format as the labels. Note that the labels are computed for\n",
    "    # all feature levels concatenated, so we keep the same representation\n",
    "    # for the objectness and the box_regression\n",
    "    for box_cls_per_level, box_regression_per_level in zip(box_cls, box_regression):\n",
    "        N, AxC, H, W = box_cls_per_level.shape\n",
    "        Ax4 = box_regression_per_level.shape[1]\n",
    "        A = Ax4 // 4\n",
    "        C = AxC // A\n",
    "        box_cls_per_level = permute_and_flatten(box_cls_per_level, N, A, C, H, W)\n",
    "        box_cls_flattened.append(box_cls_per_level)\n",
    "\n",
    "        box_regression_per_level = permute_and_flatten(box_regression_per_level, N, A, 4, H, W)\n",
    "        box_regression_flattened.append(box_regression_per_level)\n",
    "    # concatenate on the first dimension (representing the feature levels), to\n",
    "    # take into account the way the labels were generated (with all feature maps\n",
    "    # being concatenated as well)\n",
    "    box_cls = torch.cat(box_cls_flattened, dim=1).flatten(0, -2)\n",
    "    box_regression = torch.cat(box_regression_flattened, dim=1).reshape(-1, 4)\n",
    "    return box_cls, box_regression\n",
    "\n",
    "class ImageList:\n",
    "    \"\"\"\n",
    "    Structure that holds a list of images (of possibly\n",
    "    varying sizes) as a single tensor.\n",
    "    This works by padding the images to the same size,\n",
    "    and storing in a field the original sizes of each image\n",
    "    Args:\n",
    "        tensors (tensor): Tensor containing images.\n",
    "        image_sizes (list[tuple[int, int]]): List of Tuples each containing size of images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tensors: Tensor, image_sizes: List[Tuple[int, int]]) -> None:\n",
    "        self.tensors = tensors\n",
    "        self.image_sizes = image_sizes\n",
    "\n",
    "    def to(self, device: torch.device) -> \"ImageList\":\n",
    "        cast_tensor = self.tensors.to(device)\n",
    "        return ImageList(cast_tensor, self.image_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec917ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custoem ROIHeads\n",
    "\n",
    "# Rain\n",
    "class RoIHeadsRain(torchvision.models.detection.roi_heads.RoIHeads):\n",
    "    def forward(\n",
    "        self,\n",
    "        features,  # type: Dict[str, Tensor]\n",
    "        proposals,  # type: List[Tensor]\n",
    "        image_shapes,  # type: List[Tuple[int, int]]\n",
    "        targets=None,  # type: Optional[List[Dict[str, Tensor]]]\n",
    "    ):\n",
    "        if targets is not None:\n",
    "            for t in targets:\n",
    "                floating_point_types = (torch.float, torch.double, torch.half)\n",
    "                if not t[\"boxes\"].dtype in floating_point_types:\n",
    "                    raise TypeError(f\"target boxes must of float type, instead got {t['boxes'].dtype}\")\n",
    "                if not t[\"labels\"].dtype == torch.int64:\n",
    "                    raise TypeError(f\"target labels must of int64 type, instead got {t['labels'].dtype}\")\n",
    "                if self.has_keypoint():\n",
    "                    if not t[\"keypoints\"].dtype == torch.float32:\n",
    "                        raise TypeError(f\"target keypoints must of float type, instead got {t['keypoints'].dtype}\")\n",
    "\n",
    "        if self.training:\n",
    "            proposals, matched_idxs, labels, regression_targets = self.select_training_samples(proposals, targets)\n",
    "        else:\n",
    "            labels = None\n",
    "            regression_targets = None\n",
    "            matched_idxs = None\n",
    "\n",
    "        box_features = self.box_roi_pool(features, proposals, image_shapes)\n",
    "        box_features = self.box_head(box_features)\n",
    "        class_logits, box_regression = self.box_predictor(box_features)\n",
    "\n",
    "        result: List[Dict[str, torch.Tensor]] = []\n",
    "        losses = {}\n",
    "        \n",
    "        if self.training:\n",
    "            if labels is None:\n",
    "                raise ValueError(\"labels cannot be None\")\n",
    "            if regression_targets is None:\n",
    "                raise ValueError(\"regression_targets cannot be None\")\n",
    "            loss_classifier, loss_box_reg = fastrcnn_loss(class_logits, box_regression, labels, regression_targets)\n",
    "            ######MODIFIED##########\n",
    "            losses = {\"loss_classifier_rain\": loss_classifier, \"loss_box_reg_rain\": loss_box_reg}\n",
    "            ########################\n",
    "        else:\n",
    "            boxes, scores, labels = self.postprocess_detections(class_logits, box_regression, proposals, image_shapes)\n",
    "            num_images = len(boxes)\n",
    "            for i in range(num_images):\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"boxes\": boxes[i],\n",
    "                        \"labels\": labels[i],\n",
    "                        \"scores\": scores[i],\n",
    "                        \"fog\": labels[i]\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        if self.has_mask():\n",
    "            mask_proposals = [p[\"boxes\"] for p in result]\n",
    "            if self.training:\n",
    "                if matched_idxs is None:\n",
    "                    raise ValueError(\"if in training, matched_idxs should not be None\")\n",
    "\n",
    "                # during training, only focus on positive boxes\n",
    "                num_images = len(proposals)\n",
    "                mask_proposals = []\n",
    "                pos_matched_idxs = []\n",
    "                for img_id in range(num_images):\n",
    "                    pos = torch.where(labels[img_id] > 0)[0]\n",
    "                    mask_proposals.append(proposals[img_id][pos])\n",
    "                    pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "            else:\n",
    "                pos_matched_idxs = None\n",
    "\n",
    "            if self.mask_roi_pool is not None:\n",
    "                mask_features = self.mask_roi_pool(features, mask_proposals, image_shapes)\n",
    "                mask_features = self.mask_head(mask_features)\n",
    "                mask_logits = self.mask_predictor(mask_features)\n",
    "            else:\n",
    "                raise Exception(\"Expected mask_roi_pool to be not None\")\n",
    "\n",
    "            loss_mask = {}\n",
    "            if self.training:\n",
    "                if targets is None or pos_matched_idxs is None or mask_logits is None:\n",
    "                    raise ValueError(\"targets, pos_matched_idxs, mask_logits cannot be None when training\")\n",
    "\n",
    "                gt_masks = [t[\"masks\"] for t in targets]\n",
    "                gt_labels = [t[\"labels\"] for t in targets]\n",
    "                rcnn_loss_mask = maskrcnn_loss(mask_logits, mask_proposals, gt_masks, gt_labels, pos_matched_idxs)\n",
    "                loss_mask = {\"loss_mask\": rcnn_loss_mask}\n",
    "            else:\n",
    "                labels = [r[\"labels\"] for r in result]\n",
    "                masks_probs = maskrcnn_inference(mask_logits, labels)\n",
    "                for mask_prob, r in zip(masks_probs, result):\n",
    "                    r[\"masks\"] = mask_prob\n",
    "\n",
    "            losses.update(loss_mask)\n",
    "\n",
    "        # keep none checks in if conditional so torchscript will conditionally\n",
    "        # compile each branch\n",
    "        if (\n",
    "            self.keypoint_roi_pool is not None\n",
    "            and self.keypoint_head is not None\n",
    "            and self.keypoint_predictor is not None\n",
    "        ):\n",
    "            keypoint_proposals = [p[\"boxes\"] for p in result]\n",
    "            if self.training:\n",
    "                # during training, only focus on positive boxes\n",
    "                num_images = len(proposals)\n",
    "                keypoint_proposals = []\n",
    "                pos_matched_idxs = []\n",
    "                if matched_idxs is None:\n",
    "                    raise ValueError(\"if in trainning, matched_idxs should not be None\")\n",
    "\n",
    "                for img_id in range(num_images):\n",
    "                    pos = torch.where(labels[img_id] > 0)[0]\n",
    "                    keypoint_proposals.append(proposals[img_id][pos])\n",
    "                    pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "            else:\n",
    "                pos_matched_idxs = None\n",
    "\n",
    "            keypoint_features = self.keypoint_roi_pool(features, keypoint_proposals, image_shapes)\n",
    "            keypoint_features = self.keypoint_head(keypoint_features)\n",
    "            keypoint_logits = self.keypoint_predictor(keypoint_features)\n",
    "\n",
    "            loss_keypoint = {}\n",
    "            if self.training:\n",
    "                if targets is None or pos_matched_idxs is None:\n",
    "                    raise ValueError(\"both targets and pos_matched_idxs should not be None when in training mode\")\n",
    "\n",
    "                gt_keypoints = [t[\"keypoints\"] for t in targets]\n",
    "                rcnn_loss_keypoint = keypointrcnn_loss(\n",
    "                    keypoint_logits, keypoint_proposals, gt_keypoints, pos_matched_idxs\n",
    "                )\n",
    "                loss_keypoint = {\"loss_keypoint\": rcnn_loss_keypoint}\n",
    "            else:\n",
    "                if keypoint_logits is None or keypoint_proposals is None:\n",
    "                    raise ValueError(\n",
    "                        \"both keypoint_logits and keypoint_proposals should not be None when not in training mode\"\n",
    "                    )\n",
    "\n",
    "                keypoints_probs, kp_scores = keypointrcnn_inference(keypoint_logits, keypoint_proposals)\n",
    "                for keypoint_prob, kps, r in zip(keypoints_probs, kp_scores, result):\n",
    "                    r[\"keypoints\"] = keypoint_prob\n",
    "                    r[\"keypoints_scores\"] = kps\n",
    "            losses.update(loss_keypoint)\n",
    "\n",
    "        return result, losses\n",
    "\n",
    "# fog\n",
    "class RoIHeadsFog(torchvision.models.detection.roi_heads.RoIHeads):\n",
    "    def forward(\n",
    "        self,\n",
    "        features,  # type: Dict[str, Tensor]\n",
    "        proposals,  # type: List[Tensor]\n",
    "        image_shapes,  # type: List[Tuple[int, int]]\n",
    "        targets=None,  # type: Optional[List[Dict[str, Tensor]]]\n",
    "    ):\n",
    "        if targets is not None:\n",
    "            for t in targets:\n",
    "                floating_point_types = (torch.float, torch.double, torch.half)\n",
    "                if not t[\"boxes\"].dtype in floating_point_types:\n",
    "                    raise TypeError(f\"target boxes must of float type, instead got {t['boxes'].dtype}\")\n",
    "                if not t[\"labels\"].dtype == torch.int64:\n",
    "                    raise TypeError(f\"target labels must of int64 type, instead got {t['labels'].dtype}\")\n",
    "                if self.has_keypoint():\n",
    "                    if not t[\"keypoints\"].dtype == torch.float32:\n",
    "                        raise TypeError(f\"target keypoints must of float type, instead got {t['keypoints'].dtype}\")\n",
    "\n",
    "        if self.training:\n",
    "            proposals, matched_idxs, labels, regression_targets = self.select_training_samples(proposals, targets)\n",
    "        else:\n",
    "            labels = None\n",
    "            regression_targets = None\n",
    "            matched_idxs = None\n",
    "\n",
    "        box_features = self.box_roi_pool(features, proposals, image_shapes)\n",
    "        box_features = self.box_head(box_features)\n",
    "        class_logits, box_regression = self.box_predictor(box_features)\n",
    "\n",
    "        result: List[Dict[str, torch.Tensor]] = []\n",
    "        losses = {}\n",
    "        if self.training:\n",
    "            if labels is None:\n",
    "                raise ValueError(\"labels cannot be None\")\n",
    "            if regression_targets is None:\n",
    "                raise ValueError(\"regression_targets cannot be None\")\n",
    "            loss_classifier, loss_box_reg = fastrcnn_loss(class_logits, box_regression, labels, regression_targets)\n",
    "            ######MODIFIED##########\n",
    "            losses = {\"loss_classifier_fog\": loss_classifier, \"loss_box_reg_fog\": loss_box_reg}\n",
    "            ########################\n",
    "        else:\n",
    "            boxes, scores, labels = self.postprocess_detections(class_logits, box_regression, proposals, image_shapes)\n",
    "            num_images = len(boxes)\n",
    "            for i in range(num_images):\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"boxes\": boxes[i],\n",
    "                        \"labels\": labels[i],\n",
    "                        \"scores\": scores[i],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        if self.has_mask():\n",
    "            mask_proposals = [p[\"boxes\"] for p in result]\n",
    "            if self.training:\n",
    "                if matched_idxs is None:\n",
    "                    raise ValueError(\"if in training, matched_idxs should not be None\")\n",
    "\n",
    "                # during training, only focus on positive boxes\n",
    "                num_images = len(proposals)\n",
    "                mask_proposals = []\n",
    "                pos_matched_idxs = []\n",
    "                for img_id in range(num_images):\n",
    "                    pos = torch.where(labels[img_id] > 0)[0]\n",
    "                    mask_proposals.append(proposals[img_id][pos])\n",
    "                    pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "            else:\n",
    "                pos_matched_idxs = None\n",
    "\n",
    "            if self.mask_roi_pool is not None:\n",
    "                mask_features = self.mask_roi_pool(features, mask_proposals, image_shapes)\n",
    "                mask_features = self.mask_head(mask_features)\n",
    "                mask_logits = self.mask_predictor(mask_features)\n",
    "            else:\n",
    "                raise Exception(\"Expected mask_roi_pool to be not None\")\n",
    "\n",
    "            loss_mask = {}\n",
    "            if self.training:\n",
    "                if targets is None or pos_matched_idxs is None or mask_logits is None:\n",
    "                    raise ValueError(\"targets, pos_matched_idxs, mask_logits cannot be None when training\")\n",
    "\n",
    "                gt_masks = [t[\"masks\"] for t in targets]\n",
    "                gt_labels = [t[\"labels\"] for t in targets]\n",
    "                rcnn_loss_mask = maskrcnn_loss(mask_logits, mask_proposals, gt_masks, gt_labels, pos_matched_idxs)\n",
    "                loss_mask = {\"loss_mask\": rcnn_loss_mask}\n",
    "            else:\n",
    "                labels = [r[\"labels\"] for r in result]\n",
    "                masks_probs = maskrcnn_inference(mask_logits, labels)\n",
    "                for mask_prob, r in zip(masks_probs, result):\n",
    "                    r[\"masks\"] = mask_prob\n",
    "\n",
    "            losses.update(loss_mask)\n",
    "\n",
    "        # keep none checks in if conditional so torchscript will conditionally\n",
    "        # compile each branch\n",
    "        if (\n",
    "            self.keypoint_roi_pool is not None\n",
    "            and self.keypoint_head is not None\n",
    "            and self.keypoint_predictor is not None\n",
    "        ):\n",
    "            keypoint_proposals = [p[\"boxes\"] for p in result]\n",
    "            if self.training:\n",
    "                # during training, only focus on positive boxes\n",
    "                num_images = len(proposals)\n",
    "                keypoint_proposals = []\n",
    "                pos_matched_idxs = []\n",
    "                if matched_idxs is None:\n",
    "                    raise ValueError(\"if in trainning, matched_idxs should not be None\")\n",
    "\n",
    "                for img_id in range(num_images):\n",
    "                    pos = torch.where(labels[img_id] > 0)[0]\n",
    "                    keypoint_proposals.append(proposals[img_id][pos])\n",
    "                    pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "            else:\n",
    "                pos_matched_idxs = None\n",
    "\n",
    "            keypoint_features = self.keypoint_roi_pool(features, keypoint_proposals, image_shapes)\n",
    "            keypoint_features = self.keypoint_head(keypoint_features)\n",
    "            keypoint_logits = self.keypoint_predictor(keypoint_features)\n",
    "\n",
    "            loss_keypoint = {}\n",
    "            if self.training:\n",
    "                if targets is None or pos_matched_idxs is None:\n",
    "                    raise ValueError(\"both targets and pos_matched_idxs should not be None when in training mode\")\n",
    "\n",
    "                gt_keypoints = [t[\"keypoints\"] for t in targets]\n",
    "                rcnn_loss_keypoint = keypointrcnn_loss(\n",
    "                    keypoint_logits, keypoint_proposals, gt_keypoints, pos_matched_idxs\n",
    "                )\n",
    "                loss_keypoint = {\"loss_keypoint\": rcnn_loss_keypoint}\n",
    "            else:\n",
    "                if keypoint_logits is None or keypoint_proposals is None:\n",
    "                    raise ValueError(\n",
    "                        \"both keypoint_logits and keypoint_proposals should not be None when not in training mode\"\n",
    "                    )\n",
    "\n",
    "                keypoints_probs, kp_scores = keypointrcnn_inference(keypoint_logits, keypoint_proposals)\n",
    "                for keypoint_prob, kps, r in zip(keypoints_probs, kp_scores, result):\n",
    "                    r[\"keypoints\"] = keypoint_prob\n",
    "                    r[\"keypoints_scores\"] = kps\n",
    "            losses.update(loss_keypoint)\n",
    "\n",
    "        return result, losses\n",
    "\n",
    "# Night\n",
    "class RoIHeadsNight(torchvision.models.detection.roi_heads.RoIHeads):\n",
    "    def forward(\n",
    "        self,\n",
    "        features,  # type: Dict[str, Tensor]\n",
    "        proposals,  # type: List[Tensor]\n",
    "        image_shapes,  # type: List[Tuple[int, int]]\n",
    "        targets=None,  # type: Optional[List[Dict[str, Tensor]]]\n",
    "    ):\n",
    "        if targets is not None:\n",
    "            for t in targets:\n",
    "                floating_point_types = (torch.float, torch.double, torch.half)\n",
    "                if not t[\"boxes\"].dtype in floating_point_types:\n",
    "                    raise TypeError(f\"target boxes must of float type, instead got {t['boxes'].dtype}\")\n",
    "                if not t[\"labels\"].dtype == torch.int64:\n",
    "                    raise TypeError(f\"target labels must of int64 type, instead got {t['labels'].dtype}\")\n",
    "                if self.has_keypoint():\n",
    "                    if not t[\"keypoints\"].dtype == torch.float32:\n",
    "                        raise TypeError(f\"target keypoints must of float type, instead got {t['keypoints'].dtype}\")\n",
    "\n",
    "        if self.training:\n",
    "            proposals, matched_idxs, labels, regression_targets = self.select_training_samples(proposals, targets)\n",
    "        else:\n",
    "            labels = None\n",
    "            regression_targets = None\n",
    "            matched_idxs = None\n",
    "\n",
    "        box_features = self.box_roi_pool(features, proposals, image_shapes)\n",
    "        box_features = self.box_head(box_features)\n",
    "        class_logits, box_regression = self.box_predictor(box_features)\n",
    "\n",
    "        result: List[Dict[str, torch.Tensor]] = []\n",
    "        losses = {}\n",
    "        if self.training:\n",
    "            if labels is None:\n",
    "                raise ValueError(\"labels cannot be None\")\n",
    "            if regression_targets is None:\n",
    "                raise ValueError(\"regression_targets cannot be None\")\n",
    "            loss_classifier, loss_box_reg = fastrcnn_loss(class_logits, box_regression, labels, regression_targets)\n",
    "            ######MODIFIED##########\n",
    "            losses = {\"loss_classifier_night\": loss_classifier, \"loss_box_reg_night\": loss_box_reg}\n",
    "            ########################\n",
    "        else:\n",
    "            boxes, scores, labels = self.postprocess_detections(class_logits, box_regression, proposals, image_shapes)\n",
    "            num_images = len(boxes)\n",
    "            for i in range(num_images):\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"boxes\": boxes[i],\n",
    "                        \"labels\": labels[i],\n",
    "                        \"scores\": scores[i],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        if self.has_mask():\n",
    "            mask_proposals = [p[\"boxes\"] for p in result]\n",
    "            if self.training:\n",
    "                if matched_idxs is None:\n",
    "                    raise ValueError(\"if in training, matched_idxs should not be None\")\n",
    "\n",
    "                # during training, only focus on positive boxes\n",
    "                num_images = len(proposals)\n",
    "                mask_proposals = []\n",
    "                pos_matched_idxs = []\n",
    "                for img_id in range(num_images):\n",
    "                    pos = torch.where(labels[img_id] > 0)[0]\n",
    "                    mask_proposals.append(proposals[img_id][pos])\n",
    "                    pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "            else:\n",
    "                pos_matched_idxs = None\n",
    "\n",
    "            if self.mask_roi_pool is not None:\n",
    "                mask_features = self.mask_roi_pool(features, mask_proposals, image_shapes)\n",
    "                mask_features = self.mask_head(mask_features)\n",
    "                mask_logits = self.mask_predictor(mask_features)\n",
    "            else:\n",
    "                raise Exception(\"Expected mask_roi_pool to be not None\")\n",
    "\n",
    "            loss_mask = {}\n",
    "            if self.training:\n",
    "                if targets is None or pos_matched_idxs is None or mask_logits is None:\n",
    "                    raise ValueError(\"targets, pos_matched_idxs, mask_logits cannot be None when training\")\n",
    "\n",
    "                gt_masks = [t[\"masks\"] for t in targets]\n",
    "                gt_labels = [t[\"labels\"] for t in targets]\n",
    "                rcnn_loss_mask = maskrcnn_loss(mask_logits, mask_proposals, gt_masks, gt_labels, pos_matched_idxs)\n",
    "                loss_mask = {\"loss_mask\": rcnn_loss_mask}\n",
    "            else:\n",
    "                labels = [r[\"labels\"] for r in result]\n",
    "                masks_probs = maskrcnn_inference(mask_logits, labels)\n",
    "                for mask_prob, r in zip(masks_probs, result):\n",
    "                    r[\"masks\"] = mask_prob\n",
    "\n",
    "            losses.update(loss_mask)\n",
    "\n",
    "        # keep none checks in if conditional so torchscript will conditionally\n",
    "        # compile each branch\n",
    "        if (\n",
    "            self.keypoint_roi_pool is not None\n",
    "            and self.keypoint_head is not None\n",
    "            and self.keypoint_predictor is not None\n",
    "        ):\n",
    "            keypoint_proposals = [p[\"boxes\"] for p in result]\n",
    "            if self.training:\n",
    "                # during training, only focus on positive boxes\n",
    "                num_images = len(proposals)\n",
    "                keypoint_proposals = []\n",
    "                pos_matched_idxs = []\n",
    "                if matched_idxs is None:\n",
    "                    raise ValueError(\"if in trainning, matched_idxs should not be None\")\n",
    "\n",
    "                for img_id in range(num_images):\n",
    "                    pos = torch.where(labels[img_id] > 0)[0]\n",
    "                    keypoint_proposals.append(proposals[img_id][pos])\n",
    "                    pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "            else:\n",
    "                pos_matched_idxs = None\n",
    "\n",
    "            keypoint_features = self.keypoint_roi_pool(features, keypoint_proposals, image_shapes)\n",
    "            keypoint_features = self.keypoint_head(keypoint_features)\n",
    "            keypoint_logits = self.keypoint_predictor(keypoint_features)\n",
    "\n",
    "            loss_keypoint = {}\n",
    "            if self.training:\n",
    "                if targets is None or pos_matched_idxs is None:\n",
    "                    raise ValueError(\"both targets and pos_matched_idxs should not be None when in training mode\")\n",
    "\n",
    "                gt_keypoints = [t[\"keypoints\"] for t in targets]\n",
    "                rcnn_loss_keypoint = keypointrcnn_loss(\n",
    "                    keypoint_logits, keypoint_proposals, gt_keypoints, pos_matched_idxs\n",
    "                )\n",
    "                loss_keypoint = {\"loss_keypoint\": rcnn_loss_keypoint}\n",
    "            else:\n",
    "                if keypoint_logits is None or keypoint_proposals is None:\n",
    "                    raise ValueError(\n",
    "                        \"both keypoint_logits and keypoint_proposals should not be None when not in training mode\"\n",
    "                    )\n",
    "\n",
    "                keypoints_probs, kp_scores = keypointrcnn_inference(keypoint_logits, keypoint_proposals)\n",
    "                for keypoint_prob, kps, r in zip(keypoints_probs, kp_scores, result):\n",
    "                    r[\"keypoints\"] = keypoint_prob\n",
    "                    r[\"keypoints_scores\"] = kps\n",
    "            losses.update(loss_keypoint)\n",
    "\n",
    "        return result, losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37393c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RPN\n",
    "\n",
    "# rain\n",
    "class RegionProposalNetworkRain(torchvision.models.detection.rpn.RegionProposalNetwork):\n",
    "    def forward(\n",
    "        self,\n",
    "        images: ImageList,\n",
    "        features: Dict[str, Tensor],\n",
    "        targets: Optional[List[Dict[str, Tensor]]] = None,\n",
    "    ) -> Tuple[List[Tensor], Dict[str, Tensor]]:\n",
    "\n",
    "        # RPN uses all feature maps that are available\n",
    "        features = list(features.values())\n",
    "        objectness, pred_bbox_deltas = self.head(features)\n",
    "        anchors = self.anchor_generator(images, features)\n",
    "\n",
    "        num_images = len(anchors)\n",
    "        num_anchors_per_level_shape_tensors = [o[0].shape for o in objectness]\n",
    "        num_anchors_per_level = [s[0] * s[1] * s[2] for s in num_anchors_per_level_shape_tensors]\n",
    "        objectness, pred_bbox_deltas = concat_box_prediction_layers(objectness, pred_bbox_deltas)\n",
    "        # apply pred_bbox_deltas to anchors to obtain the decoded proposals\n",
    "        # note that we detach the deltas because Faster R-CNN do not backprop through\n",
    "        # the proposals\n",
    "        proposals = self.box_coder.decode(pred_bbox_deltas.detach(), anchors)\n",
    "        proposals = proposals.view(num_images, -1, 4)\n",
    "        boxes, scores = self.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)\n",
    "\n",
    "        losses = {}\n",
    "        if self.training:\n",
    "            if targets is None:\n",
    "                raise ValueError(\"targets should not be None\")\n",
    "            labels, matched_gt_boxes = self.assign_targets_to_anchors(anchors, targets)\n",
    "            regression_targets = self.box_coder.encode(matched_gt_boxes, anchors)\n",
    "            loss_objectness, loss_rpn_box_reg = self.compute_loss(\n",
    "                objectness, pred_bbox_deltas, labels, regression_targets\n",
    "            )\n",
    "            losses = {\n",
    "                #############MODIFIED###############\n",
    "                \"loss_objectness_rain\": loss_objectness,\n",
    "                \"loss_rpn_box_reg_rain\": loss_rpn_box_reg,\n",
    "                #####################################\n",
    "            }\n",
    "        return boxes, losses\n",
    "    \n",
    "    \n",
    "# fog\n",
    "class RegionProposalNetworkFog(torchvision.models.detection.rpn.RegionProposalNetwork):\n",
    "    def forward(\n",
    "        self,\n",
    "        images: ImageList,\n",
    "        features: Dict[str, Tensor],\n",
    "        targets: Optional[List[Dict[str, Tensor]]] = None,\n",
    "    ) -> Tuple[List[Tensor], Dict[str, Tensor]]:\n",
    "\n",
    "        # RPN uses all feature maps that are available\n",
    "        features = list(features.values())\n",
    "        objectness, pred_bbox_deltas = self.head(features)\n",
    "        anchors = self.anchor_generator(images, features)\n",
    "\n",
    "        num_images = len(anchors)\n",
    "        num_anchors_per_level_shape_tensors = [o[0].shape for o in objectness]\n",
    "        num_anchors_per_level = [s[0] * s[1] * s[2] for s in num_anchors_per_level_shape_tensors]\n",
    "        objectness, pred_bbox_deltas = concat_box_prediction_layers(objectness, pred_bbox_deltas)\n",
    "        # apply pred_bbox_deltas to anchors to obtain the decoded proposals\n",
    "        # note that we detach the deltas because Faster R-CNN do not backprop through\n",
    "        # the proposals\n",
    "        proposals = self.box_coder.decode(pred_bbox_deltas.detach(), anchors)\n",
    "        proposals = proposals.view(num_images, -1, 4)\n",
    "        boxes, scores = self.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)\n",
    "\n",
    "        losses = {}\n",
    "        if self.training:\n",
    "            if targets is None:\n",
    "                raise ValueError(\"targets should not be None\")\n",
    "            labels, matched_gt_boxes = self.assign_targets_to_anchors(anchors, targets)\n",
    "            regression_targets = self.box_coder.encode(matched_gt_boxes, anchors)\n",
    "            loss_objectness, loss_rpn_box_reg = self.compute_loss(\n",
    "                objectness, pred_bbox_deltas, labels, regression_targets\n",
    "            )\n",
    "            losses = {\n",
    "                #############MODIFIED###############\n",
    "                \"loss_objectness_fog\": loss_objectness,\n",
    "                \"loss_rpn_box_reg_fog\": loss_rpn_box_reg,\n",
    "                #####################################\n",
    "            }\n",
    "        return boxes, losses\n",
    "    \n",
    "    \n",
    "# night\n",
    "class RegionProposalNetworkNight(torchvision.models.detection.rpn.RegionProposalNetwork):\n",
    "    def forward(\n",
    "        self,\n",
    "        images: ImageList,\n",
    "        features: Dict[str, Tensor],\n",
    "        targets: Optional[List[Dict[str, Tensor]]] = None,\n",
    "    ) -> Tuple[List[Tensor], Dict[str, Tensor]]:\n",
    "\n",
    "        # RPN uses all feature maps that are available\n",
    "        features = list(features.values())\n",
    "        objectness, pred_bbox_deltas = self.head(features)\n",
    "        anchors = self.anchor_generator(images, features)\n",
    "\n",
    "        num_images = len(anchors)\n",
    "        num_anchors_per_level_shape_tensors = [o[0].shape for o in objectness]\n",
    "        num_anchors_per_level = [s[0] * s[1] * s[2] for s in num_anchors_per_level_shape_tensors]\n",
    "        objectness, pred_bbox_deltas = concat_box_prediction_layers(objectness, pred_bbox_deltas)\n",
    "        # apply pred_bbox_deltas to anchors to obtain the decoded proposals\n",
    "        # note that we detach the deltas because Faster R-CNN do not backprop through\n",
    "        # the proposals\n",
    "        proposals = self.box_coder.decode(pred_bbox_deltas.detach(), anchors)\n",
    "        proposals = proposals.view(num_images, -1, 4)\n",
    "        boxes, scores = self.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)\n",
    "\n",
    "        losses = {}\n",
    "        if self.training:\n",
    "            if targets is None:\n",
    "                raise ValueError(\"targets should not be None\")\n",
    "            labels, matched_gt_boxes = self.assign_targets_to_anchors(anchors, targets)\n",
    "            regression_targets = self.box_coder.encode(matched_gt_boxes, anchors)\n",
    "            loss_objectness, loss_rpn_box_reg = self.compute_loss(\n",
    "                objectness, pred_bbox_deltas, labels, regression_targets\n",
    "            )\n",
    "            losses = {\n",
    "                #############MODIFIED###############\n",
    "                \"loss_objectness_night\": loss_objectness,\n",
    "                \"loss_rpn_box_reg_night\": loss_rpn_box_reg,\n",
    "                #####################################\n",
    "            }\n",
    "        return boxes, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def make_prediction(model, img, threshold):\n",
    "    model.eval()\n",
    "    preds = model(weather, img)\n",
    "    for id in range(len(preds)) :\n",
    "        idx_list = []\n",
    "\n",
    "        for idx, score in enumerate(preds[id]['scores']) :\n",
    "            if score > threshold : \n",
    "                idx_list.append(idx)\n",
    "        preds[id]['boxes'] = preds[id]['boxes'][idx_list]\n",
    "        preds[id]['labels'] = preds[id]['labels'][idx_list]\n",
    "        preds[id]['scores'] = preds[id]['scores'][idx_list]\n",
    "\n",
    "    return preds\n",
    "\n",
    "def get_batch_statistics(outputs, targets, iou_threshold):\n",
    "    \"\"\" Compute true positives, predicted scores and predicted labels per sample \"\"\"\n",
    "    batch_metrics = []\n",
    "    for sample_i in range(len(outputs)):  # outputs=preds_adj_all, targets=annot_all\n",
    "\n",
    "        if outputs[sample_i] is None:\n",
    "            continue\n",
    "\n",
    "        output = outputs[sample_i] # predict\n",
    "        # pred_boxes = output['boxes']\n",
    "        # pred_scores = output['scores']\n",
    "        # pred_labels = output['labels']\n",
    "\n",
    "        true_positives = torch.zeros(output['boxes'].shape[0])   # The number of predicted objects\n",
    "        annotations = targets[sample_i]  # ground-truth\n",
    "        target_labels = annotations['labels'] if len(annotations) else []\n",
    "        if len(annotations):    # len(annotations) = 3\n",
    "            detected_boxes = []\n",
    "            target_boxes = annotations['boxes']\n",
    "\n",
    "            for pred_i, (pred_box, pred_label) in enumerate(zip(output['boxes'], output['labels'])): \n",
    "                \n",
    "                # If targets are found break\n",
    "                if len(detected_boxes) == len(target_labels): # annotations -> target_labels\n",
    "                    break\n",
    "\n",
    "                # Ignore if label is not one of the target labels\n",
    "                if pred_label not in target_labels:\n",
    "                    continue\n",
    "\n",
    "                iou, box_index = bbox_iou(pred_box.unsqueeze(0), target_boxes).max(0)\n",
    "                if iou >= iou_threshold and box_index not in detected_boxes: \n",
    "                    true_positives[pred_i] = 1\n",
    "                    detected_boxes += [box_index]\n",
    "        batch_metrics.append([true_positives, output['scores'], output['labels']])\n",
    "    return batch_metrics\n",
    "\n",
    "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
    "    \"\"\"\n",
    "    Returns the IoU of two bounding boxes\n",
    "    \"\"\"\n",
    "    if not x1y1x2y2:\n",
    "        # Transform from center and width to exact coordinates\n",
    "        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "    else:\n",
    "        # Get the coordinates of bounding boxes\n",
    "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "\n",
    "    # get the corrdinates of the intersection rectangle\n",
    "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "    # Intersection area\n",
    "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n",
    "    # Union Area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "    iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def ap_per_class(tp, conf, pred_cls, target_cls):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n",
    "    # Arguments\n",
    "        tp:    True positives (list).\n",
    "        conf:  Objectness value from 0-1 (list).\n",
    "        pred_cls: Predicted object classes (list).\n",
    "        target_cls: True object classes (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by objectness\n",
    "    i = torch.argsort(-conf)\n",
    "    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n",
    "\n",
    "    # Find unique classes\n",
    "    unique_classes = torch.unique(target_cls)   # 2가 거의 예측안됨\n",
    "\n",
    "    # Create Precision-Recall curve and compute AP for each class\n",
    "    ap, p, r = [], [], []\n",
    "    for c in unique_classes:\n",
    "        i = pred_cls == c\n",
    "        n_gt = (target_cls == c).sum()  # Number of ground truth objects\n",
    "        n_p = i.sum()  # Number of predicted objects\n",
    "\n",
    "        if n_p == 0 and n_gt == 0:\n",
    "            continue\n",
    "        elif n_p == 0 or n_gt == 0:\n",
    "            ap.append(0)\n",
    "            r.append(0)\n",
    "            p.append(0)\n",
    "        else:\n",
    "            # Accumulate FPs and TPs\n",
    "            fpc = torch.cumsum(1 - tp[i],-1)\n",
    "            tpc = torch.cumsum(tp[i],-1)\n",
    "\n",
    "            # Recall\n",
    "            recall_curve = tpc / (n_gt + 1e-16)\n",
    "            r.append(recall_curve[-1])\n",
    "\n",
    "            # Precision\n",
    "            precision_curve = tpc / (tpc + fpc)\n",
    "            p.append(precision_curve[-1])\n",
    "\n",
    "            # AP from recall-precision curve\n",
    "            ap.append(compute_ap(recall_curve, precision_curve))\n",
    "\n",
    "    # Compute F1 score (harmonic mean of precision and recall)\n",
    "    p, r, ap = torch.tensor(np.array(p)), torch.tensor(np.array(r)), torch.tensor(np.array(ap))\n",
    "    f1 = 2 * p * r / (p + r + 1e-16)\n",
    "\n",
    "    return p, r, ap, f1, unique_classes\n",
    "\n",
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precision, [0.0]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
